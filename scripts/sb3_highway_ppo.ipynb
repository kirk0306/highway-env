{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import requirements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gym\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pprint\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import trange\n",
    "from IPython import display as ipythondisplay\n",
    "!pip install pyvirtualdisplay\n",
    "from pyvirtualdisplay import Display\n",
    "from gym.wrappers import RecordVideo\n",
    "import base64\n",
    "# %matplotlib inline\n",
    "os.chdir('/content/drive/MyDrive/researchHub')\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 : %s\" % retval)\n",
    "path = \"highway-env\" #@param {type: \"string\"}\n",
    "os.chdir(path)\n",
    "# path = \"scripts\" #@param {type: \"string\"}\n",
    "# os.chdir(path)\n",
    "retval = os.getcwd()\n",
    "print(\"目录修改成功 : %s\" % retval)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@markdown <h3>← 在修改完的目录下安装需要的仓库\n",
    "repository = \"https://github.com/kirk0306/stable-baselines3.git\" #@param {type: \"string\"}\n",
    "branchofrepository = \"master\" #@param {type: \"string\"}\n",
    "!pip install git+{repository}@{branchofrepository}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch as th\n",
    "from stable_baselines3 import PPO\n",
    "from torch.distributions import Categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import highway_env\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train = False\n",
    "    if train:\n",
    "        n_cpu = 32\n",
    "        batch_size = 64\n",
    "        env = make_vec_env(\"merge-v0\", n_envs=n_cpu, vec_env_cls=SubprocVecEnv)\n",
    "        model = PPO(\"MlpPolicy\",\n",
    "                    env,\n",
    "                    policy_kwargs=dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])]),\n",
    "                    n_steps=24,\n",
    "                    batch_size=batch_size,\n",
    "                    n_epochs=10,\n",
    "                    learning_rate=5e-4,\n",
    "                    gamma=0.8,\n",
    "                    verbose=2,\n",
    "                    tensorboard_log=\"/content/drive/MyDrive/researchHub/highway-env/highway_ppo/\")\n",
    "        # Train the agent\n",
    "        # model_loaded = PPO.load(\"/content/drive/MyDrive/researchHub/highway-env/highway_ppo/model\")\n",
    "        # model.set_parameters(model_loaded.get_parameters())\n",
    "        model.learn(total_timesteps=int(3e5))\n",
    "        # Save the agent\n",
    "        model.save(\"/content/drive/MyDrive/researchHub/highway-env/highway_ppo/model\")\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "    model = PPO.load(\"/content/drive/MyDrive/researchHub/highway-env/highway_ppo/model\", device=\"cpu\")\n",
    "    env = gym.make(\"merge-v0\")\n",
    "    env = RecordVideo(env, video_folder='/content/drive/MyDrive/researchHub/highway-env/highway_ppo/videos', episode_trigger=lambda e: True)\n",
    "    env.unwrapped.set_record_video_wrapper(env)\n",
    "    env.configure({\"offscreen_rendering\": True})\n",
    "    img = env.render(mode='rgb_array')\n",
    "\n",
    "    for _ in range(55):\n",
    "        obs = env.reset()\n",
    "        done = [False]\n",
    "        # while not all(done):\n",
    "        action, _ = model.predict(obs)\n",
    "        # obs, reward, done, info = env.step(np.array([0,0],dtype=np.float32))\n",
    "        obs, reward, done, info = env.step(tuple([a for a in action]))\n",
    "        env.render()       \n",
    "            # time.sleep(0.3)\n",
    "        # env.close()\n",
    "    plt.imshow(env.render(mode=\"rgb_array\"))\n",
    "    plt.show()\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.13 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}